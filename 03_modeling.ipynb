{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Arabic-Stopwords\n",
      "  Downloading Arabic_Stopwords-0.3-py3-none-any.whl (353 kB)\n",
      "Collecting pyarabic>=0.6.2\n",
      "  Downloading PyArabic-0.6.14-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\omar wael\\anaconda3\\lib\\site-packages (from pyarabic>=0.6.2->Arabic-Stopwords) (1.16.0)\n",
      "Installing collected packages: pyarabic, Arabic-Stopwords\n",
      "Successfully installed Arabic-Stopwords-0.3 pyarabic-0.6.14\n"
     ]
    }
   ],
   "source": [
    "!pip install Arabic-Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.2-py3-none-win_amd64.whl (106.6 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\omar wael\\anaconda3\\lib\\site-packages (from xgboost) (1.22.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\omar wael\\anaconda3\\lib\\site-packages (from xgboost) (1.7.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import arabicstopwords.arabicstopwords as stp\n",
    "\n",
    "#vectorization\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#models \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_file_path = '../data/cleaned_dialect_dataset.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and viewing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = pd.read_excel(cleaned_file_path,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_len</th>\n",
       "      <th>stem_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>285367</th>\n",
       "      <td>4.498899e+17</td>\n",
       "      <td>EG</td>\n",
       "      <td>مين اللى بيبيع الضمير ويشتري بيه الدمار حدوتة مصرية</td>\n",
       "      <td>51</td>\n",
       "      <td>مين للى يبع ضمر شتر بيه دمر حدت صرة</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208129</th>\n",
       "      <td>1.136754e+18</td>\n",
       "      <td>SA</td>\n",
       "      <td>ترى جالس ابكي بدون دموع خلاص ماتحمل قلبي رهيف</td>\n",
       "      <td>67</td>\n",
       "      <td>ترى جلس ابك بدن دمع خلص ماتحمل قلب رهف</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41554</th>\n",
       "      <td>1.142942e+18</td>\n",
       "      <td>LY</td>\n",
       "      <td>مايسترو بلرز مثلا مش مارة عليك</td>\n",
       "      <td>42</td>\n",
       "      <td>مايسترو لرز ثلا مش ارة علك</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246095</th>\n",
       "      <td>1.158793e+18</td>\n",
       "      <td>EG</td>\n",
       "      <td>عن الخلاف بين قادة وشباب الاخوان في تركيا حول العنف والإرهاب ما يسمونه ب \"العمل النوعي\" واللي كان ترحيل الشاب عبد الحفيظ \"أحد أعضاء تيار العنف الارهاب محمد كمال العمل النوعي\" من تركيا لمصر حلقة صارخة من حلقاته لأي شخص مكانش بايت بره مصر الشهور اللي فاتت</td>\n",
       "      <td>280</td>\n",
       "      <td>عن خلف بين قدة شبب اخو في ترك حول عنف رهب ما سمو ب `` عمل نوع '' ولل كان رحل شاب عبد حفظ `` احد عضء تير عنف رهب حمد كمل عمل نوع '' من ترك مصر حلق صرخ من حلق لأي شخص كنش بيت بره مصر شهر الل فتت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345596</th>\n",
       "      <td>7.097478e+17</td>\n",
       "      <td>KW</td>\n",
       "      <td>اول مره تختار شي صح احلام</td>\n",
       "      <td>50</td>\n",
       "      <td>اول مره خار شي صح حلم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167024</th>\n",
       "      <td>1.024334e+18</td>\n",
       "      <td>JO</td>\n",
       "      <td>الاخ الكبير مظلوم ومضطهد الأخ الكبير هو السند بعد الأب هو صمام الأمان الثاني في البيت هو اللي ممكن يتنازل عن شغلات عشان اخوانه وأخواته❤️</td>\n",
       "      <td>139</td>\n",
       "      <td>الخ كبر ظلم ضطهد لأخ كبر هو سند بعد لأب هو صمم امن ثني في بيت هو الل مكن نزل عن شغل عشن خون وأخواته❤️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48331</th>\n",
       "      <td>1.105023e+18</td>\n",
       "      <td>LY</td>\n",
       "      <td>علي العموم ابو ظبي كويسه في الصحه وممتازة للأجازات ربي يوفقهم ان شاءالله وسلم علي الشهداء اللي معاك ياصديقنا شوفلنا سيرجيو بلكي يديرلنا راي في اجازة حتي في ابو ظبي راضي بيها عادي نهارك طيب ياصديقنا</td>\n",
       "      <td>215</td>\n",
       "      <td>علي عمم ابو ظبي كوس في صحه متز اجز ربي وفق ان شاءالل سلم علي شهداء الل عاك صدق شوفل رجو بلك ديرل راي في جزة حتي في ابو ظبي رضي بيه عدي نهر طيب صدق</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181155</th>\n",
       "      <td>1.098325e+18</td>\n",
       "      <td>MA</td>\n",
       "      <td>ترى مو قصدي حب حب عادي يعني متابعني اكيد ماتكرهني الا اذا عندك انفصام</td>\n",
       "      <td>80</td>\n",
       "      <td>ترى مو قصد حب حب عدي يعن تبع اكد اكر الا اذا عند فصم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359084</th>\n",
       "      <td>1.136306e+18</td>\n",
       "      <td>KW</td>\n",
       "      <td>معناته احنا صح فطرنا امس</td>\n",
       "      <td>42</td>\n",
       "      <td>عنت احن صح فطر امس</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422809</th>\n",
       "      <td>1.943070e+17</td>\n",
       "      <td>AE</td>\n",
       "      <td>قــلوب الوان والـنـيه عـيـون والـبـشر مـابـيـن مـزمـار وطـبل بيـن شعـرة عـقـل وانـواع الجـنـون صـفي الـنيه يشـوفـونـه خـبـل</td>\n",
       "      <td>136</td>\n",
       "      <td>قــلوب وان ـنـ عــ ـبـشر مـابـيـن مـزمـار طـبل بيـ شعـر عـقـل ـوع جـنـ صـف ـنه يشـوفـونـه خـبـل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107696</th>\n",
       "      <td>1.045649e+18</td>\n",
       "      <td>PL</td>\n",
       "      <td>ياريت حد يخبرها انو العين ملهاش خلق تطرق هيك اشكال  وانو لما بدها تصيب بتصيب شخص عليه القيمه مش حضرتها يا الهي كمية الزناااخة</td>\n",
       "      <td>146</td>\n",
       "      <td>يري حد خبر انو عين لهش خلق طرق هيك شكل ونو لما بده تصب تصب شخص عليه قيم مش حضر يا اله كمة زناااخ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360166</th>\n",
       "      <td>8.974961e+17</td>\n",
       "      <td>KW</td>\n",
       "      <td>بل السايق و الطباخ يجي مجانا بس يحتاج فيزاء</td>\n",
       "      <td>60</td>\n",
       "      <td>بل سيق و طبخ يجي مجا بس حاج يزء</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181426</th>\n",
       "      <td>1.079410e+18</td>\n",
       "      <td>MA</td>\n",
       "      <td>له هذا من وين جابوه</td>\n",
       "      <td>25</td>\n",
       "      <td>له هذا من وين جبه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40951</th>\n",
       "      <td>8.529801e+17</td>\n",
       "      <td>LY</td>\n",
       "      <td>مبروك علينا و عليكم</td>\n",
       "      <td>43</td>\n",
       "      <td>برك علي و علي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145578</th>\n",
       "      <td>5.594321e+17</td>\n",
       "      <td>TN</td>\n",
       "      <td>توة المسؤولين يقولو \"وفرنا قارورة جهاز و زودنا الكيوسكات ب ألف مليون ترليون مليار لتر</td>\n",
       "      <td>138</td>\n",
       "      <td>توة سؤل قولو `` وفر قرر جهز و زود كيس ب الف ملي ترل لير لتر</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id dialect  \\\n",
       "285367  4.498899e+17      EG   \n",
       "208129  1.136754e+18      SA   \n",
       "41554   1.142942e+18      LY   \n",
       "246095  1.158793e+18      EG   \n",
       "345596  7.097478e+17      KW   \n",
       "167024  1.024334e+18      JO   \n",
       "48331   1.105023e+18      LY   \n",
       "181155  1.098325e+18      MA   \n",
       "359084  1.136306e+18      KW   \n",
       "422809  1.943070e+17      AE   \n",
       "107696  1.045649e+18      PL   \n",
       "360166  8.974961e+17      KW   \n",
       "181426  1.079410e+18      MA   \n",
       "40951   8.529801e+17      LY   \n",
       "145578  5.594321e+17      TN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                  text  \\\n",
       "285367                                                                                                                                                                                                             مين اللى بيبيع الضمير ويشتري بيه الدمار حدوتة مصرية   \n",
       "208129                                                                                                                                                                                                                   ترى جالس ابكي بدون دموع خلاص ماتحمل قلبي رهيف   \n",
       "41554                                                                                                                                                                                                                                  مايسترو بلرز مثلا مش مارة عليك    \n",
       "246095  عن الخلاف بين قادة وشباب الاخوان في تركيا حول العنف والإرهاب ما يسمونه ب \"العمل النوعي\" واللي كان ترحيل الشاب عبد الحفيظ \"أحد أعضاء تيار العنف الارهاب محمد كمال العمل النوعي\" من تركيا لمصر حلقة صارخة من حلقاته لأي شخص مكانش بايت بره مصر الشهور اللي فاتت    \n",
       "345596                                                                                                                                                                                                                                      اول مره تختار شي صح احلام    \n",
       "167024                                                                                                                       الاخ الكبير مظلوم ومضطهد الأخ الكبير هو السند بعد الأب هو صمام الأمان الثاني في البيت هو اللي ممكن يتنازل عن شغلات عشان اخوانه وأخواته❤️    \n",
       "48331                                                           علي العموم ابو ظبي كويسه في الصحه وممتازة للأجازات ربي يوفقهم ان شاءالله وسلم علي الشهداء اللي معاك ياصديقنا شوفلنا سيرجيو بلكي يديرلنا راي في اجازة حتي في ابو ظبي راضي بيها عادي نهارك طيب ياصديقنا    \n",
       "181155                                                                                                                                                                                           ترى مو قصدي حب حب عادي يعني متابعني اكيد ماتكرهني الا اذا عندك انفصام   \n",
       "359084                                                                                                                                                                                                                                        معناته احنا صح فطرنا امس   \n",
       "422809                                                                                                                                    قــلوب الوان والـنـيه عـيـون والـبـشر مـابـيـن مـزمـار وطـبل بيـن شعـرة عـقـل وانـواع الجـنـون صـفي الـنيه يشـوفـونـه خـبـل    \n",
       "107696                                                                                                                                  ياريت حد يخبرها انو العين ملهاش خلق تطرق هيك اشكال  وانو لما بدها تصيب بتصيب شخص عليه القيمه مش حضرتها يا الهي كمية الزناااخة    \n",
       "360166                                                                                                                                                                                                                     بل السايق و الطباخ يجي مجانا بس يحتاج فيزاء   \n",
       "181426                                                                                                                                                                                                                                            له هذا من وين جابوه    \n",
       "40951                                                                                                                                                                                                                                             مبروك علينا و عليكم    \n",
       "145578                                                                                                                                                                          توة المسؤولين يقولو \"وفرنا قارورة جهاز و زودنا الكيوسكات ب ألف مليون ترليون مليار لتر    \n",
       "\n",
       "        tweet_len  \\\n",
       "285367         51   \n",
       "208129         67   \n",
       "41554          42   \n",
       "246095        280   \n",
       "345596         50   \n",
       "167024        139   \n",
       "48331         215   \n",
       "181155         80   \n",
       "359084         42   \n",
       "422809        136   \n",
       "107696        146   \n",
       "360166         60   \n",
       "181426         25   \n",
       "40951          43   \n",
       "145578        138   \n",
       "\n",
       "                                                                                                                                                                                               stem_text  \n",
       "285367                                                                                                                                                               مين للى يبع ضمر شتر بيه دمر حدت صرة  \n",
       "208129                                                                                                                                                            ترى جلس ابك بدن دمع خلص ماتحمل قلب رهف  \n",
       "41554                                                                                                                                                                         مايسترو لرز ثلا مش ارة علك  \n",
       "246095  عن خلف بين قدة شبب اخو في ترك حول عنف رهب ما سمو ب `` عمل نوع '' ولل كان رحل شاب عبد حفظ `` احد عضء تير عنف رهب حمد كمل عمل نوع '' من ترك مصر حلق صرخ من حلق لأي شخص كنش بيت بره مصر شهر الل فتت  \n",
       "345596                                                                                                                                                                             اول مره خار شي صح حلم  \n",
       "167024                                                                                             الخ كبر ظلم ضطهد لأخ كبر هو سند بعد لأب هو صمم امن ثني في بيت هو الل مكن نزل عن شغل عشن خون وأخواته❤️  \n",
       "48331                                                 علي عمم ابو ظبي كوس في صحه متز اجز ربي وفق ان شاءالل سلم علي شهداء الل عاك صدق شوفل رجو بلك ديرل راي في جزة حتي في ابو ظبي رضي بيه عدي نهر طيب صدق  \n",
       "181155                                                                                                                                              ترى مو قصد حب حب عدي يعن تبع اكد اكر الا اذا عند فصم  \n",
       "359084                                                                                                                                                                                عنت احن صح فطر امس  \n",
       "422809                                                                                                   قــلوب وان ـنـ عــ ـبـشر مـابـيـن مـزمـار طـبل بيـ شعـر عـقـل ـوع جـنـ صـف ـنه يشـوفـونـه خـبـل  \n",
       "107696                                                                                                  يري حد خبر انو عين لهش خلق طرق هيك شكل ونو لما بده تصب تصب شخص عليه قيم مش حضر يا اله كمة زناااخ  \n",
       "360166                                                                                                                                                                   بل سيق و طبخ يجي مجا بس حاج يزء  \n",
       "181426                                                                                                                                                                                 له هذا من وين جبه  \n",
       "40951                                                                                                                                                                                      برك علي و علي  \n",
       "145578                                                                                                                                       توة سؤل قولو `` وفر قرر جهز و زود كيس ب الف ملي ترل لير لتر  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply label Encoding on our target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  8, 12, 11, 15, 16,  5,  9, 13, 17,  2,  3,  7,  6, 10, 14,  0,\n",
       "        1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder=preprocessing.LabelEncoder ()\n",
    "cleaned_df['dialect_labels'] =label_encoder.fit_transform (cleaned_df['dialect'])\n",
    "cleaned_df['dialect_labels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_len</th>\n",
       "      <th>stem_text</th>\n",
       "      <th>dialect_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.175358e+18</td>\n",
       "      <td>IQ</td>\n",
       "      <td>لكن بالنهاية ينتفض يغير</td>\n",
       "      <td>48</td>\n",
       "      <td>لكن نهي نفض يغر</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.175416e+18</td>\n",
       "      <td>IQ</td>\n",
       "      <td>يعني هذا محسوب على البشر حيونه ووحشيه وتطلبون من الغرب يحترمكم ويؤمن بدينكم ولاينعتكم بالإرهاب</td>\n",
       "      <td>120</td>\n",
       "      <td>يعن هذا حسب على بشر حين وحش طلب من غرب حرم يؤم بدن ينع رهب</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.175450e+18</td>\n",
       "      <td>IQ</td>\n",
       "      <td>مبين من كلامه خليجي</td>\n",
       "      <td>31</td>\n",
       "      <td>بين من كلم خلج</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.175471e+18</td>\n",
       "      <td>IQ</td>\n",
       "      <td>يسلملي مرورك وروحك الحلوه</td>\n",
       "      <td>42</td>\n",
       "      <td>لمل رور ورح حله</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.175497e+18</td>\n",
       "      <td>IQ</td>\n",
       "      <td>وين هل الغيبه اخ محمد</td>\n",
       "      <td>34</td>\n",
       "      <td>وين هل غيب اخ حمد</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458192</th>\n",
       "      <td>1.019485e+18</td>\n",
       "      <td>BH</td>\n",
       "      <td>مبسوطين منك اللي باسطا</td>\n",
       "      <td>37</td>\n",
       "      <td>بسط منك الل بسط</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458193</th>\n",
       "      <td>1.021083e+18</td>\n",
       "      <td>BH</td>\n",
       "      <td>والله ماينده ابش يختي</td>\n",
       "      <td>44</td>\n",
       "      <td>ولل ايند ابش يخت</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458194</th>\n",
       "      <td>1.017478e+18</td>\n",
       "      <td>BH</td>\n",
       "      <td>شو عملنا لك حنا تهربي مننا احنا مساكين ليش بتعملي هيك فينا</td>\n",
       "      <td>73</td>\n",
       "      <td>شو عمل لك حنا هرب ننا احن ساك ليش عمل هيك فين</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458195</th>\n",
       "      <td>1.022430e+18</td>\n",
       "      <td>BH</td>\n",
       "      <td>الله يبارك فيها وبالعافيه</td>\n",
       "      <td>43</td>\n",
       "      <td>الل يبر فيه وبالعافيه</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458196</th>\n",
       "      <td>1.022410e+18</td>\n",
       "      <td>BH</td>\n",
       "      <td>السحله ضيفي ي بتطلع لك سحليه</td>\n",
       "      <td>41</td>\n",
       "      <td>سحل ضيف ي طلع لك سحل</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458152 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id dialect  \\\n",
       "0       1.175358e+18      IQ   \n",
       "1       1.175416e+18      IQ   \n",
       "2       1.175450e+18      IQ   \n",
       "3       1.175471e+18      IQ   \n",
       "4       1.175497e+18      IQ   \n",
       "...              ...     ...   \n",
       "458192  1.019485e+18      BH   \n",
       "458193  1.021083e+18      BH   \n",
       "458194  1.017478e+18      BH   \n",
       "458195  1.022430e+18      BH   \n",
       "458196  1.022410e+18      BH   \n",
       "\n",
       "                                                                                                    text  \\\n",
       "0                                                                               لكن بالنهاية ينتفض يغير    \n",
       "1        يعني هذا محسوب على البشر حيونه ووحشيه وتطلبون من الغرب يحترمكم ويؤمن بدينكم ولاينعتكم بالإرهاب    \n",
       "2                                                                                    مبين من كلامه خليجي   \n",
       "3                                                                              يسلملي مرورك وروحك الحلوه   \n",
       "4                                                                                 وين هل الغيبه اخ محمد    \n",
       "...                                                                                                  ...   \n",
       "458192                                                                            مبسوطين منك اللي باسطا   \n",
       "458193                                                                             والله ماينده ابش يختي   \n",
       "458194                                       شو عملنا لك حنا تهربي مننا احنا مساكين ليش بتعملي هيك فينا    \n",
       "458195                                                                        الله يبارك فيها وبالعافيه    \n",
       "458196                                                                      السحله ضيفي ي بتطلع لك سحليه   \n",
       "\n",
       "        tweet_len                                                   stem_text  \\\n",
       "0              48                                             لكن نهي نفض يغر   \n",
       "1             120  يعن هذا حسب على بشر حين وحش طلب من غرب حرم يؤم بدن ينع رهب   \n",
       "2              31                                              بين من كلم خلج   \n",
       "3              42                                             لمل رور ورح حله   \n",
       "4              34                                           وين هل غيب اخ حمد   \n",
       "...           ...                                                         ...   \n",
       "458192         37                                             بسط منك الل بسط   \n",
       "458193         44                                            ولل ايند ابش يخت   \n",
       "458194         73               شو عمل لك حنا هرب ننا احن ساك ليش عمل هيك فين   \n",
       "458195         43                                       الل يبر فيه وبالعافيه   \n",
       "458196         41                                        سحل ضيف ي طلع لك سحل   \n",
       "\n",
       "        dialect_labels  \n",
       "0                    4  \n",
       "1                    4  \n",
       "2                    4  \n",
       "3                    4  \n",
       "4                    4  \n",
       "...                ...  \n",
       "458192               1  \n",
       "458193               1  \n",
       "458194               1  \n",
       "458195               1  \n",
       "458196               1  \n",
       "\n",
       "[458152 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one row in the x_train is null which make a problem with countvectorizer\n",
    "cleaned_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to remove stopwords\n",
    "there is another idea to pass stopwords array to countvectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "stopwords=set(stopwords.words(\"arabic\"))\n",
    "'لكن' in stopwords\n",
    "#Contains 700 stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words=wordpunct_tokenize(text)\n",
    "\n",
    "    filtered_sentence=[]\n",
    "\n",
    "    for i in words:\n",
    "        if i not in stopwords:\n",
    "          filtered_sentence.append(i)\n",
    "    return \" \".join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'كتب الولد الدرس الذى المدرسة'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=\"كتب الولد الدرس الذى كان هو ف المدرسة\"\n",
    "remove_stopwords(test)\n",
    "#great it's works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply it on cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_len</th>\n",
       "      <th>stem_text</th>\n",
       "      <th>dialect_labels</th>\n",
       "      <th>text_without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.175358e+18</td>\n",
       "      <td>IQ</td>\n",
       "      <td>لكن بالنهاية ينتفض يغير</td>\n",
       "      <td>48</td>\n",
       "      <td>لكن نهي نفض يغر</td>\n",
       "      <td>4</td>\n",
       "      <td>بالنهاية ينتفض يغير</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.175416e+18</td>\n",
       "      <td>IQ</td>\n",
       "      <td>يعني هذا محسوب على البشر حيونه ووحشيه وتطلبون من الغرب يحترمكم ويؤمن بدينكم ولاينعتكم بالإرهاب</td>\n",
       "      <td>120</td>\n",
       "      <td>يعن هذا حسب على بشر حين وحش طلب من غرب حرم يؤم بدن ينع رهب</td>\n",
       "      <td>4</td>\n",
       "      <td>يعني محسوب البشر حيونه ووحشيه وتطلبون الغرب يحترمكم ويؤمن بدينكم ولاينعتكم بالإرهاب</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.175450e+18</td>\n",
       "      <td>IQ</td>\n",
       "      <td>مبين من كلامه خليجي</td>\n",
       "      <td>31</td>\n",
       "      <td>بين من كلم خلج</td>\n",
       "      <td>4</td>\n",
       "      <td>مبين كلامه خليجي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.175471e+18</td>\n",
       "      <td>IQ</td>\n",
       "      <td>يسلملي مرورك وروحك الحلوه</td>\n",
       "      <td>42</td>\n",
       "      <td>لمل رور ورح حله</td>\n",
       "      <td>4</td>\n",
       "      <td>يسلملي مرورك وروحك الحلوه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.175497e+18</td>\n",
       "      <td>IQ</td>\n",
       "      <td>وين هل الغيبه اخ محمد</td>\n",
       "      <td>34</td>\n",
       "      <td>وين هل غيب اخ حمد</td>\n",
       "      <td>4</td>\n",
       "      <td>وين الغيبه اخ محمد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458192</th>\n",
       "      <td>1.019485e+18</td>\n",
       "      <td>BH</td>\n",
       "      <td>مبسوطين منك اللي باسطا</td>\n",
       "      <td>37</td>\n",
       "      <td>بسط منك الل بسط</td>\n",
       "      <td>1</td>\n",
       "      <td>مبسوطين منك اللي باسطا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458193</th>\n",
       "      <td>1.021083e+18</td>\n",
       "      <td>BH</td>\n",
       "      <td>والله ماينده ابش يختي</td>\n",
       "      <td>44</td>\n",
       "      <td>ولل ايند ابش يخت</td>\n",
       "      <td>1</td>\n",
       "      <td>والله ماينده ابش يختي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458194</th>\n",
       "      <td>1.017478e+18</td>\n",
       "      <td>BH</td>\n",
       "      <td>شو عملنا لك حنا تهربي مننا احنا مساكين ليش بتعملي هيك فينا</td>\n",
       "      <td>73</td>\n",
       "      <td>شو عمل لك حنا هرب ننا احن ساك ليش عمل هيك فين</td>\n",
       "      <td>1</td>\n",
       "      <td>شو عملنا حنا تهربي مننا احنا مساكين ليش بتعملي هيك فينا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458195</th>\n",
       "      <td>1.022430e+18</td>\n",
       "      <td>BH</td>\n",
       "      <td>الله يبارك فيها وبالعافيه</td>\n",
       "      <td>43</td>\n",
       "      <td>الل يبر فيه وبالعافيه</td>\n",
       "      <td>1</td>\n",
       "      <td>الله يبارك وبالعافيه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458196</th>\n",
       "      <td>1.022410e+18</td>\n",
       "      <td>BH</td>\n",
       "      <td>السحله ضيفي ي بتطلع لك سحليه</td>\n",
       "      <td>41</td>\n",
       "      <td>سحل ضيف ي طلع لك سحل</td>\n",
       "      <td>1</td>\n",
       "      <td>السحله ضيفي بتطلع سحليه</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458151 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id dialect  \\\n",
       "0       1.175358e+18      IQ   \n",
       "1       1.175416e+18      IQ   \n",
       "2       1.175450e+18      IQ   \n",
       "3       1.175471e+18      IQ   \n",
       "4       1.175497e+18      IQ   \n",
       "...              ...     ...   \n",
       "458192  1.019485e+18      BH   \n",
       "458193  1.021083e+18      BH   \n",
       "458194  1.017478e+18      BH   \n",
       "458195  1.022430e+18      BH   \n",
       "458196  1.022410e+18      BH   \n",
       "\n",
       "                                                                                                    text  \\\n",
       "0                                                                               لكن بالنهاية ينتفض يغير    \n",
       "1        يعني هذا محسوب على البشر حيونه ووحشيه وتطلبون من الغرب يحترمكم ويؤمن بدينكم ولاينعتكم بالإرهاب    \n",
       "2                                                                                    مبين من كلامه خليجي   \n",
       "3                                                                              يسلملي مرورك وروحك الحلوه   \n",
       "4                                                                                 وين هل الغيبه اخ محمد    \n",
       "...                                                                                                  ...   \n",
       "458192                                                                            مبسوطين منك اللي باسطا   \n",
       "458193                                                                             والله ماينده ابش يختي   \n",
       "458194                                       شو عملنا لك حنا تهربي مننا احنا مساكين ليش بتعملي هيك فينا    \n",
       "458195                                                                        الله يبارك فيها وبالعافيه    \n",
       "458196                                                                      السحله ضيفي ي بتطلع لك سحليه   \n",
       "\n",
       "        tweet_len                                                   stem_text  \\\n",
       "0              48                                             لكن نهي نفض يغر   \n",
       "1             120  يعن هذا حسب على بشر حين وحش طلب من غرب حرم يؤم بدن ينع رهب   \n",
       "2              31                                              بين من كلم خلج   \n",
       "3              42                                             لمل رور ورح حله   \n",
       "4              34                                           وين هل غيب اخ حمد   \n",
       "...           ...                                                         ...   \n",
       "458192         37                                             بسط منك الل بسط   \n",
       "458193         44                                            ولل ايند ابش يخت   \n",
       "458194         73               شو عمل لك حنا هرب ننا احن ساك ليش عمل هيك فين   \n",
       "458195         43                                       الل يبر فيه وبالعافيه   \n",
       "458196         41                                        سحل ضيف ي طلع لك سحل   \n",
       "\n",
       "        dialect_labels  \\\n",
       "0                    4   \n",
       "1                    4   \n",
       "2                    4   \n",
       "3                    4   \n",
       "4                    4   \n",
       "...                ...   \n",
       "458192               1   \n",
       "458193               1   \n",
       "458194               1   \n",
       "458195               1   \n",
       "458196               1   \n",
       "\n",
       "                                                                     text_without_stopwords  \n",
       "0                                                                       بالنهاية ينتفض يغير  \n",
       "1       يعني محسوب البشر حيونه ووحشيه وتطلبون الغرب يحترمكم ويؤمن بدينكم ولاينعتكم بالإرهاب  \n",
       "2                                                                          مبين كلامه خليجي  \n",
       "3                                                                 يسلملي مرورك وروحك الحلوه  \n",
       "4                                                                        وين الغيبه اخ محمد  \n",
       "...                                                                                     ...  \n",
       "458192                                                               مبسوطين منك اللي باسطا  \n",
       "458193                                                                والله ماينده ابش يختي  \n",
       "458194                              شو عملنا حنا تهربي مننا احنا مساكين ليش بتعملي هيك فينا  \n",
       "458195                                                                 الله يبارك وبالعافيه  \n",
       "458196                                                              السحله ضيفي بتطلع سحليه  \n",
       "\n",
       "[458151 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df['text_without_stopwords'] = cleaned_df.text.apply(remove_stopwords)\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply it on stemming text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_len</th>\n",
       "      <th>stem_text</th>\n",
       "      <th>dialect_labels</th>\n",
       "      <th>text_without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.175358e+18</td>\n",
       "      <td>IQ</td>\n",
       "      <td>لكن بالنهاية ينتفض يغير</td>\n",
       "      <td>48</td>\n",
       "      <td>نهي نفض يغر</td>\n",
       "      <td>4</td>\n",
       "      <td>بالنهاية ينتفض يغير</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.175416e+18</td>\n",
       "      <td>IQ</td>\n",
       "      <td>يعني هذا محسوب على البشر حيونه ووحشيه وتطلبون من الغرب يحترمكم ويؤمن بدينكم ولاينعتكم بالإرهاب</td>\n",
       "      <td>120</td>\n",
       "      <td>يعن بشر وحش طلب غرب حرم يؤم بدن ينع رهب</td>\n",
       "      <td>4</td>\n",
       "      <td>يعني محسوب البشر حيونه ووحشيه وتطلبون الغرب يحترمكم ويؤمن بدينكم ولاينعتكم بالإرهاب</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.175450e+18</td>\n",
       "      <td>IQ</td>\n",
       "      <td>مبين من كلامه خليجي</td>\n",
       "      <td>31</td>\n",
       "      <td>كلم خلج</td>\n",
       "      <td>4</td>\n",
       "      <td>مبين كلامه خليجي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.175471e+18</td>\n",
       "      <td>IQ</td>\n",
       "      <td>يسلملي مرورك وروحك الحلوه</td>\n",
       "      <td>42</td>\n",
       "      <td>لمل رور ورح حله</td>\n",
       "      <td>4</td>\n",
       "      <td>يسلملي مرورك وروحك الحلوه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.175497e+18</td>\n",
       "      <td>IQ</td>\n",
       "      <td>وين هل الغيبه اخ محمد</td>\n",
       "      <td>34</td>\n",
       "      <td>وين غيب اخ حمد</td>\n",
       "      <td>4</td>\n",
       "      <td>وين الغيبه اخ محمد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458192</th>\n",
       "      <td>1.019485e+18</td>\n",
       "      <td>BH</td>\n",
       "      <td>مبسوطين منك اللي باسطا</td>\n",
       "      <td>37</td>\n",
       "      <td>بسط منك الل بسط</td>\n",
       "      <td>1</td>\n",
       "      <td>مبسوطين منك اللي باسطا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458193</th>\n",
       "      <td>1.021083e+18</td>\n",
       "      <td>BH</td>\n",
       "      <td>والله ماينده ابش يختي</td>\n",
       "      <td>44</td>\n",
       "      <td>ولل ايند ابش يخت</td>\n",
       "      <td>1</td>\n",
       "      <td>والله ماينده ابش يختي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458194</th>\n",
       "      <td>1.017478e+18</td>\n",
       "      <td>BH</td>\n",
       "      <td>شو عملنا لك حنا تهربي مننا احنا مساكين ليش بتعملي هيك فينا</td>\n",
       "      <td>73</td>\n",
       "      <td>شو عمل حنا هرب ننا احن ساك ليش عمل هيك فين</td>\n",
       "      <td>1</td>\n",
       "      <td>شو عملنا حنا تهربي مننا احنا مساكين ليش بتعملي هيك فينا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458195</th>\n",
       "      <td>1.022430e+18</td>\n",
       "      <td>BH</td>\n",
       "      <td>الله يبارك فيها وبالعافيه</td>\n",
       "      <td>43</td>\n",
       "      <td>الل يبر وبالعافيه</td>\n",
       "      <td>1</td>\n",
       "      <td>الله يبارك وبالعافيه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458196</th>\n",
       "      <td>1.022410e+18</td>\n",
       "      <td>BH</td>\n",
       "      <td>السحله ضيفي ي بتطلع لك سحليه</td>\n",
       "      <td>41</td>\n",
       "      <td>سحل ضيف طلع سحل</td>\n",
       "      <td>1</td>\n",
       "      <td>السحله ضيفي بتطلع سحليه</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458151 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id dialect  \\\n",
       "0       1.175358e+18      IQ   \n",
       "1       1.175416e+18      IQ   \n",
       "2       1.175450e+18      IQ   \n",
       "3       1.175471e+18      IQ   \n",
       "4       1.175497e+18      IQ   \n",
       "...              ...     ...   \n",
       "458192  1.019485e+18      BH   \n",
       "458193  1.021083e+18      BH   \n",
       "458194  1.017478e+18      BH   \n",
       "458195  1.022430e+18      BH   \n",
       "458196  1.022410e+18      BH   \n",
       "\n",
       "                                                                                                    text  \\\n",
       "0                                                                               لكن بالنهاية ينتفض يغير    \n",
       "1        يعني هذا محسوب على البشر حيونه ووحشيه وتطلبون من الغرب يحترمكم ويؤمن بدينكم ولاينعتكم بالإرهاب    \n",
       "2                                                                                    مبين من كلامه خليجي   \n",
       "3                                                                              يسلملي مرورك وروحك الحلوه   \n",
       "4                                                                                 وين هل الغيبه اخ محمد    \n",
       "...                                                                                                  ...   \n",
       "458192                                                                            مبسوطين منك اللي باسطا   \n",
       "458193                                                                             والله ماينده ابش يختي   \n",
       "458194                                       شو عملنا لك حنا تهربي مننا احنا مساكين ليش بتعملي هيك فينا    \n",
       "458195                                                                        الله يبارك فيها وبالعافيه    \n",
       "458196                                                                      السحله ضيفي ي بتطلع لك سحليه   \n",
       "\n",
       "        tweet_len                                   stem_text  dialect_labels  \\\n",
       "0              48                                 نهي نفض يغر               4   \n",
       "1             120     يعن بشر وحش طلب غرب حرم يؤم بدن ينع رهب               4   \n",
       "2              31                                     كلم خلج               4   \n",
       "3              42                             لمل رور ورح حله               4   \n",
       "4              34                              وين غيب اخ حمد               4   \n",
       "...           ...                                         ...             ...   \n",
       "458192         37                             بسط منك الل بسط               1   \n",
       "458193         44                            ولل ايند ابش يخت               1   \n",
       "458194         73  شو عمل حنا هرب ننا احن ساك ليش عمل هيك فين               1   \n",
       "458195         43                           الل يبر وبالعافيه               1   \n",
       "458196         41                             سحل ضيف طلع سحل               1   \n",
       "\n",
       "                                                                     text_without_stopwords  \n",
       "0                                                                       بالنهاية ينتفض يغير  \n",
       "1       يعني محسوب البشر حيونه ووحشيه وتطلبون الغرب يحترمكم ويؤمن بدينكم ولاينعتكم بالإرهاب  \n",
       "2                                                                          مبين كلامه خليجي  \n",
       "3                                                                 يسلملي مرورك وروحك الحلوه  \n",
       "4                                                                        وين الغيبه اخ محمد  \n",
       "...                                                                                     ...  \n",
       "458192                                                               مبسوطين منك اللي باسطا  \n",
       "458193                                                                والله ماينده ابش يختي  \n",
       "458194                              شو عملنا حنا تهربي مننا احنا مساكين ليش بتعملي هيك فينا  \n",
       "458195                                                                 الله يبارك وبالعافيه  \n",
       "458196                                                              السحله ضيفي بتطلع سحليه  \n",
       "\n",
       "[458151 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df['stem_text'] = cleaned_df.stem_text.apply(remove_stopwords)\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "    1- working with stemming data\n",
    "     \n",
    "    2- working with unstemmed data (only cleaned)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IQ', 'LY', 'QA', 'PL', 'SY', 'TN', 'JO', 'MA', 'SA', 'YE', 'DZ',\n",
       "       'EG', 'LB', 'KW', 'OM', 'SD', 'AE', 'BH'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.dialect.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a global method to prediction and print report\n",
    "def print_report(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    report = metrics.classification_report(y_test, y_pred,target_names=cleaned_df.dialect.unique())\n",
    "    print(report)\n",
    "    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 :Working with stemming data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split stemming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows of Total dataset : 458151\n",
      "Number of rows of Train dataset : 366520\n",
      "Number of rows of Test dataset : 91631\n"
     ]
    }
   ],
   "source": [
    "X = cleaned_df['stem_text']\n",
    "y = cleaned_df['dialect_labels']\n",
    "\n",
    "# new_X = pd.Series([str (item) for item in X])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "print('Number of rows of Total dataset : {}'.format(cleaned_df.shape[0]))\n",
    "print('Number of rows of Train dataset : {}'.format(X_train.shape[0]))\n",
    "print('Number of rows of Test dataset : {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>Count Vectorizer and tfidf transformer \n",
    "- with MultinomialNB accuracy: 0.453 \n",
    "- with SGDClassifier accuracy: 0.423</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "training_data = count_vec.fit_transform(X_train)\n",
    "testing_data = count_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((366520, 111120), (91631, 111120))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape,testing_data.shape\n",
    "#as seen there are 111120 words as a feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>TfidfTransformer : using countvectorizer then tfidftransformer is equivalent to tfidfvectorizer</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "training_data = tfidf.fit_transform(training_data)\n",
    "testing_data = tfidf.transform(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifier for multinomial models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB(alpha=0.08)\n",
    "mnb.fit(training_data, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IQ       0.40      0.27      0.32      5337\n",
      "          LY       0.36      0.20      0.26      5269\n",
      "          QA       0.71      0.35      0.47      3249\n",
      "          PL       0.52      0.88      0.66     11595\n",
      "          SY       0.81      0.35      0.49      3045\n",
      "          TN       0.41      0.18      0.25      5561\n",
      "          JO       0.32      0.65      0.43      8374\n",
      "          MA       0.61      0.54      0.58      5562\n",
      "          SA       0.55      0.59      0.57      7356\n",
      "          YE       0.89      0.42      0.57      2289\n",
      "          DZ       0.53      0.14      0.22      3855\n",
      "          EG       0.34      0.61      0.43      8692\n",
      "          LB       0.41      0.42      0.42      6204\n",
      "          KW       0.40      0.31      0.35      5398\n",
      "          OM       0.82      0.31      0.45      2855\n",
      "          SD       0.60      0.13      0.21      3226\n",
      "          AE       0.82      0.19      0.31      1754\n",
      "          BH       0.63      0.06      0.12      2010\n",
      "\n",
      "    accuracy                           0.45     91631\n",
      "   macro avg       0.56      0.37      0.39     91631\n",
      "weighted avg       0.50      0.45      0.43     91631\n",
      "\n",
      "accuracy: 0.453\n"
     ]
    }
   ],
   "source": [
    "print_report(mnb, testing_data, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGDClassifier (Linear support vector machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(loss='hinge',alpha=1e-3, random_state=42)\n",
    "sgd.fit(training_data, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IQ       0.32      0.28      0.30      5337\n",
      "          LY       0.33      0.17      0.22      5269\n",
      "          QA       0.44      0.38      0.41      3249\n",
      "          PL       0.49      0.87      0.63     11595\n",
      "          SY       0.46      0.49      0.48      3045\n",
      "          TN       0.31      0.18      0.22      5561\n",
      "          JO       0.42      0.46      0.44      8374\n",
      "          MA       0.47      0.62      0.54      5562\n",
      "          SA       0.48      0.56      0.52      7356\n",
      "          YE       0.54      0.51      0.52      2289\n",
      "          DZ       0.29      0.19      0.23      3855\n",
      "          EG       0.41      0.37      0.39      8692\n",
      "          LB       0.38      0.41      0.40      6204\n",
      "          KW       0.36      0.24      0.29      5398\n",
      "          OM       0.41      0.28      0.33      2855\n",
      "          SD       0.33      0.15      0.21      3226\n",
      "          AE       0.43      0.31      0.36      1754\n",
      "          BH       0.18      0.16      0.17      2010\n",
      "\n",
      "    accuracy                           0.42     91631\n",
      "   macro avg       0.39      0.37      0.37     91631\n",
      "weighted avg       0.40      0.42      0.40     91631\n",
      "\n",
      "accuracy: 0.423\n"
     ]
    }
   ],
   "source": [
    "print_report(sgd, testing_data, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2 : working with cleaned data only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split unstem data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows of Total dataset : 458151\n",
      "Number of rows of Train dataset : 366520\n",
      "Number of rows of Test dataset : 91631\n"
     ]
    }
   ],
   "source": [
    "X = cleaned_df['text']\n",
    "y = cleaned_df['dialect_labels']\n",
    "\n",
    "# new_X = pd.Series([str (item) for item in X])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "print('Number of rows of Total dataset : {}'.format(cleaned_df.shape[0]))\n",
    "print('Number of rows of Train dataset : {}'.format(X_train.shape[0]))\n",
    "print('Number of rows of Test dataset : {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>Count vectorizer\n",
    "- with MultinomialNB, accuracy:  0.554 <strong>Is the best result I got</strong> \n",
    "- with SGD, accuracy: 0.490 </strong> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "training_data = count_vec.fit_transform(X_train)\n",
    "testing_data = count_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((366520, 436338), (91631, 436338))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape,testing_data.shape\n",
    "#as seen there are 436338 words as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB(alpha=0.08)\n",
    "mnb.fit(training_data, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IQ       0.42      0.44      0.43      5337\n",
      "          LY       0.35      0.35      0.35      5269\n",
      "          QA       0.65      0.57      0.61      3249\n",
      "          PL       0.73      0.88      0.80     11595\n",
      "          SY       0.70      0.55      0.61      3045\n",
      "          TN       0.44      0.35      0.39      5561\n",
      "          JO       0.48      0.57      0.52      8374\n",
      "          MA       0.67      0.68      0.67      5562\n",
      "          SA       0.73      0.70      0.71      7356\n",
      "          YE       0.80      0.62      0.69      2289\n",
      "          DZ       0.45      0.33      0.38      3855\n",
      "          EG       0.47      0.59      0.53      8692\n",
      "          LB       0.45      0.51      0.48      6204\n",
      "          KW       0.42      0.45      0.43      5398\n",
      "          OM       0.77      0.57      0.66      2855\n",
      "          SD       0.49      0.31      0.38      3226\n",
      "          AE       0.70      0.45      0.54      1754\n",
      "          BH       0.44      0.18      0.26      2010\n",
      "\n",
      "    accuracy                           0.55     91631\n",
      "   macro avg       0.56      0.51      0.52     91631\n",
      "weighted avg       0.56      0.55      0.55     91631\n",
      "\n",
      "accuracy: 0.554\n"
     ]
    }
   ],
   "source": [
    "print_report(mnb, testing_data, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(loss='hinge',alpha=1e-3, random_state=42) #loss=hinge which gives a linear svm\n",
    "sgd.fit(training_data, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IQ       0.42      0.36      0.39      5337\n",
      "          LY       0.33      0.24      0.28      5269\n",
      "          QA       0.53      0.49      0.51      3249\n",
      "          PL       0.57      0.88      0.69     11595\n",
      "          SY       0.51      0.56      0.53      3045\n",
      "          TN       0.42      0.23      0.29      5561\n",
      "          JO       0.47      0.56      0.51      8374\n",
      "          MA       0.51      0.68      0.58      5562\n",
      "          SA       0.58      0.64      0.61      7356\n",
      "          YE       0.57      0.55      0.56      2289\n",
      "          DZ       0.34      0.29      0.31      3855\n",
      "          EG       0.49      0.43      0.46      8692\n",
      "          LB       0.46      0.45      0.45      6204\n",
      "          KW       0.42      0.38      0.40      5398\n",
      "          OM       0.58      0.41      0.48      2855\n",
      "          SD       0.38      0.21      0.27      3226\n",
      "          AE       0.63      0.39      0.48      1754\n",
      "          BH       0.23      0.16      0.19      2010\n",
      "\n",
      "    accuracy                           0.49     91631\n",
      "   macro avg       0.47      0.44      0.44     91631\n",
      "weighted avg       0.48      0.49      0.47     91631\n",
      "\n",
      "accuracy: 0.490\n"
     ]
    }
   ],
   "source": [
    "print_report(sgd, testing_data, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong> Tfidf vecotrizer \n",
    "- with MultinomialNB accuracy: 0.524\n",
    "- with SGD, accuracy: 0.504\n",
    "</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True)\n",
    "training_data = vectorizer.fit_transform(X_train)\n",
    "testing_data = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((366520, 436338), (91631, 436338))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape,testing_data.shape\n",
    "#as seen there are 436338 words as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.08)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=0.08)\n",
    "mnb.fit(training_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IQ       0.46      0.38      0.41      5337\n",
      "          LY       0.39      0.27      0.32      5269\n",
      "          QA       0.79      0.46      0.58      3249\n",
      "          PL       0.61      0.92      0.73     11595\n",
      "          SY       0.85      0.40      0.55      3045\n",
      "          TN       0.46      0.27      0.34      5561\n",
      "          JO       0.38      0.68      0.49      8374\n",
      "          MA       0.69      0.64      0.66      5562\n",
      "          SA       0.66      0.70      0.68      7356\n",
      "          YE       0.94      0.52      0.67      2289\n",
      "          DZ       0.61      0.20      0.30      3855\n",
      "          EG       0.39      0.66      0.49      8692\n",
      "          LB       0.44      0.51      0.47      6204\n",
      "          KW       0.46      0.39      0.42      5398\n",
      "          OM       0.93      0.39      0.55      2855\n",
      "          SD       0.69      0.16      0.25      3226\n",
      "          AE       0.95      0.25      0.40      1754\n",
      "          BH       0.77      0.07      0.12      2010\n",
      "\n",
      "    accuracy                           0.52     91631\n",
      "   macro avg       0.64      0.44      0.47     91631\n",
      "weighted avg       0.57      0.52      0.50     91631\n",
      "\n",
      "accuracy: 0.524\n"
     ]
    }
   ],
   "source": [
    "print_report(mnb, testing_data, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(loss='hinge',alpha=1e-3, random_state=42)\n",
    "sgd.fit(training_data, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IQ       0.45      0.38      0.41      5337\n",
      "          LY       0.41      0.25      0.31      5269\n",
      "          QA       0.56      0.49      0.52      3249\n",
      "          PL       0.52      0.91      0.66     11595\n",
      "          SY       0.56      0.56      0.56      3045\n",
      "          TN       0.46      0.24      0.32      5561\n",
      "          JO       0.48      0.57      0.53      8374\n",
      "          MA       0.53      0.71      0.60      5562\n",
      "          SA       0.57      0.66      0.61      7356\n",
      "          YE       0.62      0.57      0.59      2289\n",
      "          DZ       0.42      0.29      0.34      3855\n",
      "          EG       0.50      0.46      0.48      8692\n",
      "          LB       0.45      0.47      0.46      6204\n",
      "          KW       0.46      0.36      0.41      5398\n",
      "          OM       0.57      0.38      0.45      2855\n",
      "          SD       0.45      0.20      0.27      3226\n",
      "          AE       0.58      0.40      0.47      1754\n",
      "          BH       0.37      0.16      0.22      2010\n",
      "\n",
      "    accuracy                           0.50     91631\n",
      "   macro avg       0.50      0.45      0.46     91631\n",
      "weighted avg       0.50      0.50      0.48     91631\n",
      "\n",
      "accuracy: 0.504\n"
     ]
    }
   ],
   "source": [
    "print_report(sgd, testing_data, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network \n",
    "- incompleted (since I have issue with my laptop resource, I need to make hyperparamter tuning to get better) accuracy :0.3750477433204651"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows of Total dataset : 458151\n",
      "Number of rows of Train dataset : 366520\n",
      "Number of rows of Test dataset : 91631\n"
     ]
    }
   ],
   "source": [
    "X = cleaned_df['text']\n",
    "y = cleaned_df['dialect_labels']\n",
    "\n",
    "# new_X = pd.Series([str (item) for item in X])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "print('Number of rows of Total dataset : {}'.format(cleaned_df.shape[0]))\n",
    "print('Number of rows of Train dataset : {}'.format(X_train.shape[0]))\n",
    "print('Number of rows of Test dataset : {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize.fit_on_texts(X_train) # only fit on train\n",
    "x_train = tokenize.texts_to_matrix(X_train)\n",
    "x_test = tokenize.texts_to_matrix(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : i have some problems with my laptop - MemoryError: Unable to allocate 13.7 GiB for an array with shape (366520, 5000) and data type float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 16)                16016     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 18)                306       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,322\n",
      "Trainable params: 16,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(16,input_shape=(input_shape,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(18,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 18)\n",
    "y_test = to_categorical(y_test, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (366520, 1000)\n",
      "x_test shape: (91631, 1000)\n",
      "y_train shape: (366520, 18, 18)\n",
      "y_test shape: (91631, 18, 18)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 18, 18) and (None, 18) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\OMARWA~1\\AppData\\Local\\Temp/ipykernel_2076/3749084926.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(x_train, y_train,\n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     validation_split=0.2)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\Omar Wael\\Anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 18, 18) and (None, 18) are incompatible\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=2,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2864/2864 [==============================] - 23s 8ms/step - loss: 1.9636 - accuracy: 0.3750\n",
      "Test accuracy: 0.3750477433204651\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=32, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare best result for deployment\n",
    "- Count vectorizer with MutlinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows of Total dataset : 458151\n",
      "Number of rows of Train dataset : 366520\n",
      "Number of rows of Test dataset : 91631\n"
     ]
    }
   ],
   "source": [
    "X = cleaned_df['text']\n",
    "y = cleaned_df['dialect_labels']\n",
    "\n",
    "# new_X = pd.Series([str (item) for item in X])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "print('Number of rows of Total dataset : {}'.format(cleaned_df.shape[0]))\n",
    "print('Number of rows of Train dataset : {}'.format(X_train.shape[0]))\n",
    "print('Number of rows of Test dataset : {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                ('model', MultinomialNB(alpha=0.08))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(steps= [('vec', CountVectorizer()),\n",
    "                            ('model', MultinomialNB(alpha=0.08))])\n",
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IQ       0.42      0.44      0.43      5337\n",
      "          LY       0.35      0.35      0.35      5269\n",
      "          QA       0.65      0.57      0.61      3249\n",
      "          PL       0.73      0.88      0.80     11595\n",
      "          SY       0.70      0.55      0.61      3045\n",
      "          TN       0.44      0.35      0.39      5561\n",
      "          JO       0.48      0.57      0.52      8374\n",
      "          MA       0.67      0.68      0.67      5562\n",
      "          SA       0.73      0.70      0.71      7356\n",
      "          YE       0.80      0.62      0.69      2289\n",
      "          DZ       0.45      0.33      0.38      3855\n",
      "          EG       0.47      0.59      0.53      8692\n",
      "          LB       0.45      0.51      0.48      6204\n",
      "          KW       0.42      0.45      0.43      5398\n",
      "          OM       0.77      0.57      0.66      2855\n",
      "          SD       0.49      0.31      0.38      3226\n",
      "          AE       0.70      0.45      0.54      1754\n",
      "          BH       0.44      0.18      0.26      2010\n",
      "\n",
      "    accuracy                           0.55     91631\n",
      "   macro avg       0.56      0.51      0.52     91631\n",
      "weighted avg       0.56      0.55      0.55     91631\n",
      "\n",
      "accuracy: 0.554\n"
     ]
    }
   ],
   "source": [
    "print_report(pipeline,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model.joblib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(pipeline, filename=\"best_model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "485a7b116eb3a8ad65ddd739a567e9f72c40a9d95ef486baa58e0ff3eb709032"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
